package astparser

import (
	"backend/internal/lib/utils"

	"errors"
	"flag"
	"fmt"
	"go/ast"
	"go/format"
	"go/parser"
	"go/printer"
	"go/token"
	"log"
	"os"
	"strings"

	"gopkg.in/yaml.v3"
)

type Flags struct {
	in   *string
	out  *string
	meta *string
	pkg  *string
}

func parseFlags() (*Flags, error) {
	// Parse program arguments
	var flags Flags
	flags.in = flag.String("in", "", "input go file")
	flags.out = flag.String("out", "", "output go file")
	flags.meta = flag.String("meta", "", "metadata yaml")
	flags.pkg = flag.String("pkg", "schemas", "name of the package")
	flag.Parse()
	if *flags.in == "" || *flags.meta == "" || *flags.out == "" {
		return &flags, errors.New("usage: taggen -in <raw.go> -meta <metadata.yaml> -out <output.go>")
	}
	return &flags, nil
}

type FieldMeta struct {
	Type          string `yaml:"type"`
	JSON          string `yaml:"json"`
	BSON          string `yaml:"bson"`
	Validate      string `yaml:"validate"`
	Description   string `yaml:"description"`
	Default       string `yaml:"default"`
	Example       string `yaml:"example"`
	FilterExample string `yaml:"filter-example"`
	SwaggerIgnore string `yaml:"swaggerignore"`
}

type Config struct {
	Imports     []string             `yaml:"imports"`
	Fields      map[string]FieldMeta `yaml:"fields"`
	Selectables []string             `yaml:"selectables"`
	Sortables   []string             `yaml:"sortables"`
}

func parseYaml(flags *Flags) (Config, error) {
	// parse the yaml file
	var config Config
	metaData, err := os.ReadFile(*flags.meta)
	if err != nil {
		return config, err
	}
	err = yaml.Unmarshal(metaData, &config)
	if err != nil {
		return config, err
	}

	sortables := make([]string, 0, len(config.Sortables)*2)
	for _, field := range config.Sortables {
		sortables = append(sortables, field)
		sortables = append(sortables, "-"+field)
	}
	config.Sortables = sortables
	return config, err
}

func getFileBuilder(
	flags *Flags,
) (*ast.File, *token.FileSet, *strings.Builder, error) {
	var fileBuilder strings.Builder

	// Parse the raw go file
	fset := token.NewFileSet()
	node, err := parser.ParseFile(fset, *flags.in, nil, parser.ParseComments)
	if err != nil {
		return node, fset, &fileBuilder, err
	}

	fileBuilder.WriteString("// Code generated by go generate; DO NOT EDIT.\n")
	fileBuilder.WriteString("package " + *flags.pkg + "\n\n")
	return node, fset, &fileBuilder, nil
}

func addImports(
	node *ast.File, config Config, fileBuilder *strings.Builder,
) error {
	var fileImports []string
	for _, imp := range node.Imports {
		fileImports = append(fileImports, imp.Path.Value)
	}

	var configImports []string
	for _, imp := range config.Imports {
		configImports = append(configImports, "\""+imp+"\"")
	}

	allImports := utils.MergeUnique(fileImports, configImports)
	if len(allImports) == 0 {
		return nil
	}

	fileBuilder.WriteString("import (\n")
	for _, imp := range allImports {
		fileBuilder.WriteString("\t" + imp + "\n")
	}
	fileBuilder.WriteString(")\n\n")
	return nil
}

const SchemasPrefix = "schemas:"

type SchemasCommand string

const (
	SkipCmd    SchemasCommand = "skip"
	TagCmd     SchemasCommand = "tag"
	FiltersCmd SchemasCommand = "filters"
)

func parseCommand(group *ast.CommentGroup) SchemasCommand {
	if group == nil {
		return SkipCmd
	}

	text := strings.TrimSpace(group.Text())
	if !strings.HasPrefix(text, string(SchemasPrefix)) {
		return SkipCmd
	}

	cmd := strings.TrimSpace(strings.TrimPrefix(text, string(SchemasPrefix)))
	parsed := SchemasCommand(cmd)
	switch parsed {
	case TagCmd, FiltersCmd:
		return parsed
	default:
		return SkipCmd
	}
}

func iterateOverDeclarations(
	node *ast.File,
	fset *token.FileSet,
	config Config,
	fileBuilder *strings.Builder,
) error {
	for _, decl := range node.Decls {
		switch d := decl.(type) {
		case *ast.GenDecl:
			switch d.Tok {
			case token.IMPORT:
				// Imports were already handled
				continue
			case token.CONST, token.VAR:
				fileBuilder.WriteString(nodeToGoCode(decl, fset) + "\n")
			case token.TYPE:
				cmd := parseCommand(d.Doc)
				if cmd == SkipCmd {
					fileBuilder.WriteString(nodeToGoCode(decl, fset) + "\n")
				} else {
					if len(d.Specs) > 1 {
						return errors.New("schemas directive should not be used with block of structs definition")
					}
					typeSpec := d.Specs[0].(*ast.TypeSpec)
					structType, ok := typeSpec.Type.(*ast.StructType)
					if !ok {
						return errors.New("schemas directive should be used with structs only")
					}
					err := processCmd(cmd, structType, typeSpec.Name.Name, config, fileBuilder)
					if err != nil {
						return err
					}
				}
			}

		case *ast.FuncDecl:
			fileBuilder.WriteString(nodeToGoCode(decl, fset) + "\n")
		}
	}
	return nil
}

func nodeToGoCode(node ast.Node, fset *token.FileSet) string {
	var buf strings.Builder
	printer.Fprint(&buf, fset, node)
	return buf.String()
}

func processCmd(
	cmd SchemasCommand,
	typeSpec *ast.StructType,
	name string,
	config Config,
	fileBuilder *strings.Builder,
) error {
	var err error

	switch cmd {
	case TagCmd:
		err = annotateStructDefinition(
			typeSpec,
			name,
			config,
			fileBuilder,
		)
	case FiltersCmd:
		err = buildFilters(typeSpec, name, config, fileBuilder)

	default:
		err = fmt.Errorf("invalid schemas command: %s", cmd)
	}
	return err
}

type FieldTransformer struct {
	names       []string
	typeStr     string
	annotations map[string]string
	comment     string
	meta        *FieldMeta
	required    bool
	targetTag   string
	jsonOption  string
	tagOptions  []string
}

func (ft *FieldTransformer) MergedNames() string {
	return strings.Join(ft.names, ", ")
}

func (ft *FieldTransformer) AnnotationString() string {
	var parts []string

	val, exists := ft.annotations["json"]
	if exists {
		parts = append(parts, fmt.Sprintf("json:\"%s\"", val))
	}

	val, exists = ft.annotations["form"]
	if exists {
		parts = append(parts, fmt.Sprintf("form:\"%s\"", val))
	}

	val, exists = ft.annotations["filter"]
	if exists {
		parts = append(parts, fmt.Sprintf("filter:\"%s\"", val))
	}

	val, exists = ft.annotations["validate"]
	if exists {
		parts = append(parts, fmt.Sprintf("validate:\"%s\"", val))
	}

	val, exists = ft.annotations["default"]
	if exists {
		parts = append(parts, fmt.Sprintf("default:\"%s\"", val))
	} else {
		// No point of writing an example if a default value is provided
		val, exists = ft.annotations["example"]
		if exists {
			parts = append(parts, fmt.Sprintf("example:\"%s\"", val))
		}
	}

	val, exists = ft.annotations["bson"]
	if exists {
		parts = append(parts, fmt.Sprintf("bson:\"%s\"", val))
	}

	val, exists = ft.annotations["swaggerignore"]
	if exists {
		parts = append(parts, fmt.Sprintf("swaggerignore:\"%s\"", val))
	}

	merged := strings.Join(parts, " ")
	if merged == "" {
		return ""
	}
	return "`" + merged + "`"
}

func (ft *FieldTransformer) String() string {
	result := ft.MergedNames() + " " + ft.typeStr
	annotations := ft.AnnotationString()
	if annotations != "" {
		result = result + " " + annotations
	}
	if ft.comment != "" {
		result = result + " // " + ft.comment
	}
	return strings.TrimSpace(result)
}

func (ft *FieldTransformer) LoadConfig(config Config, cmd SchemasCommand) error {
	meta, exists := config.Fields[ft.targetTag]
	if !exists {
		return fmt.Errorf("no config for field(s) %s", ft.MergedNames())
	}
	ft.meta = &meta

	switch cmd {
	case FiltersCmd:
		// Generating filters schema mode
		ft.typeStr = "[]string"
		ft.updateFiltersAnnotations()
		ft.comment = ft.meta.Description
	default:
		// Annotating schemas mode
		if ft.typeStr == "any" && meta.Type != "" {
			ft.typeStr = meta.Type
		}
		ft.updateSchemasAnnotations()
		ft.comment = ft.meta.Description
	}

	return nil
}

func (ft *FieldTransformer) updateSchemasAnnotations() {
	// JSON tag
	if ft.jsonOption != "" {
		ft.annotations["json"] = strings.TrimSpace(ft.jsonOption)
	} else if ft.meta.JSON != "" {
		ft.annotations["json"] = strings.TrimSpace(ft.meta.JSON)
	} else {
		ft.annotations["json"] = ft.targetTag
	}

	// BSON tag
	if ft.meta.BSON != "" {
		ft.annotations["bson"] = strings.TrimSpace(ft.meta.BSON)
	} else {
		ft.annotations["bson"] = ft.annotations["json"]
	}

	// Validate tag
	validate := ""
	if ft.required {
		validate = "required"
	}
	if ft.meta.Validate != "" {
		validate = validate + "," + ft.meta.Validate
	}
	if validate != "" {
		ft.annotations["validate"] = strings.Trim(validate, ",")
	}

	// Example tag
	if ft.meta.Example != "" {
		ft.annotations["example"] = ft.meta.Example
	}

	// SwaggerIgnore
	if ft.meta.SwaggerIgnore == "true" {
		ft.annotations["swaggerignore"] = "true"
	}
}

func (ft *FieldTransformer) updateFiltersAnnotations() {
	// JSON tag
	if ft.jsonOption != "" {
		ft.annotations["json"] = strings.TrimSpace(ft.jsonOption)
	} else if ft.meta.JSON != "" {
		ft.annotations["json"] = strings.TrimSpace(ft.meta.JSON)
	} else {
		ft.annotations["json"] = ft.targetTag
	}

	// Filter tag
	filter := ft.meta.Type
	if ft.meta.Validate != "" {
		filter = filter + "," + ft.meta.Validate
	}
	if len(ft.tagOptions) > 0 {
		filter = filter + "," + strings.Join(ft.tagOptions, ",")
	}
	if filter != "" {
		ft.annotations["filter"] = strings.Trim(filter, ",")
	}

	// Example tag
	if ft.meta.FilterExample != "" {
		ft.annotations["example"] = ft.meta.FilterExample
	}
}

func parseFieldType(expr ast.Expr) string {
	switch t := expr.(type) {
	case *ast.Ident:
		return t.Name
	case *ast.ArrayType:
		return "[]" + parseFieldType(t.Elt)
	case *ast.StarExpr:
		return "*" + parseFieldType(t.X)
	case *ast.InterfaceType:
		return "any"
	default:
		return "any"
	}
}

func parseFieldTags(tags *ast.BasicLit) map[string]string {
	result := make(map[string]string)
	if tags == nil {
		return result
	}

	rawTagsStr := strings.Trim(tags.Value, "`")
	for _, tag := range strings.Split(rawTagsStr, " ") {
		if tag == "" {
			continue
		}

		parts := strings.SplitN(tag, ":", 2)
		if len(parts) == 2 {
			result[parts[0]] = strings.Trim(parts[1], "\"")
		} else {
			result[parts[0]] = ""
		}
	}

	return result
}

func newAnnotatedField(field *ast.Field) FieldTransformer {
	names := make([]string, 0, len(field.Names))
	for _, n := range field.Names {
		names = append(names, n.Name)
	}
	typeStr := parseFieldType(field.Type)
	annotations := parseFieldTags(field.Tag)
	targetTag, exists := annotations["tag"]
	if exists {
		delete(annotations, "tag")
	}

	// targetTag example tage:"title,optional,indexed,json=titleX"
	targetTagParts := strings.Split(targetTag, ",")

	// Extract the targetTag name
	targetTag = strings.TrimSpace(targetTagParts[0])
	tagOptions := targetTagParts[1:]

	// Check if field is optional or not
	tagOptions, isOptional := utils.RemoveFromList(tagOptions, "optional")
	required := !isOptional

	// Check if a json flag was specified
	tagOptions, jsonOption := utils.RemoveReFromList(tagOptions, "json=")
	jsonOption = strings.TrimPrefix(jsonOption, "json=")

	return FieldTransformer{
		names:       names,
		typeStr:     typeStr,
		required:    required,
		annotations: annotations,
		targetTag:   targetTag,
		jsonOption:  jsonOption,
		tagOptions:  tagOptions,
	}
}

func annotateStructDefinition(
	structType *ast.StructType,
	name string,
	config Config,
	fileBuilder *strings.Builder,
) error {
	fileBuilder.WriteString("\ntype " + name + " struct {\n")

	for _, field := range structType.Fields.List {
		a := newAnnotatedField(field)
		if a.targetTag != "" {
			err := a.LoadConfig(config, TagCmd)
			if err != nil {
				return err
			}
		}
		newLine := a.String()
		fileBuilder.WriteString(newLine + "\n")
	}
	fileBuilder.WriteString("}\n\n")
	return nil
}

func buildFilters(
	structType *ast.StructType,
	name string,
	config Config,
	fileBuilder *strings.Builder,
) error {
	// Write struct heade
	fileBuilder.WriteString("\ntype " + name + " struct {\n")

	// Write Page field
	fileBuilder.WriteString("\tPage\tstring\t`json:\"page\"`\n")

	// Write Size field
	fileBuilder.WriteString("\tSize\tstring\t`json:\"size\"`\n")

	// Write Sort field
	sortOptions := strings.Join(config.Sortables, " ")
	sortLine := fmt.Sprintf("Sort []string `json:\"sort\" validate:\"dive,oneof=%s\"`", sortOptions)
	fileBuilder.WriteString("\t" + sortLine + "\n")

	// Write Fields field
	fieldsOptions := strings.Join(config.Selectables, " ")
	fieldsLine := fmt.Sprintf("Fields []string `json:\"fields\" validate:\"dive,oneof=%s\"`", fieldsOptions)
	fileBuilder.WriteString("\t" + fieldsLine + "\n")

	// Write the field filters
	for _, field := range structType.Fields.List {
		a := newAnnotatedField(field)
		a.typeStr = "[]string"
		if a.targetTag != "" {
			err := a.LoadConfig(config, FiltersCmd)
			if err != nil {
				return err
			}
		}
		newLine := a.String()
		fileBuilder.WriteString(newLine + "\n")
	}

	// Write struct tail
	fileBuilder.WriteString("}\n\n")

	return nil
}

func ParseSchemaFile() {
	// Step 1: parse arguments
	flags, err := parseFlags()
	if err != nil {
		log.Fatal(err.Error())
	}

	// Step 2: parsing yaml data
	config, err := parseYaml(flags)
	if err != nil {
		log.Fatal(err.Error())
	}

	// Step 3: parsing go file
	node, fset, fileBuilder, err := getFileBuilder(flags)
	if err != nil {
		log.Fatal(err.Error())
	}

	// Step 4: Add imports
	err = addImports(node, config, fileBuilder)
	if err != nil {
		log.Fatal(err.Error())
	}

	// Step 5: Iterate over declarations
	err = iterateOverDeclarations(node, fset, config, fileBuilder)
	if err != nil {
		log.Fatalf("Warning: formatting failed: %v", err)
	}

	// Step 6: Parsing the generated go code
	formatted, err := format.Source([]byte(fileBuilder.String()))
	if err != nil {
		log.Fatalf("Warning: formatting failed: %v", err)
	}

	// Step 7: Writing the annotaed go file
	if err := os.WriteFile(*flags.out, formatted, 0644); err != nil {
		log.Fatal(err)
	}

	fmt.Printf("Generated %s successfully!\n", *flags.out)
}
